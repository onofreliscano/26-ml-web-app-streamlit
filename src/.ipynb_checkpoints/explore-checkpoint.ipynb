{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/workspace/workspace/github/26-ml-web-app-streamlit/src/src/.streamlit',\n",
       "  '/workspace/workspace/github/26-ml-web-app-streamlit/src/src/models',\n",
       "  '/workspace/workspace/github/26-ml-web-app-streamlit/src/src/scripts'],\n",
       " 'OK')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLOQUE 01\n",
    "# BOOTSTRAP DEL PROYECTO (EJECUTAR EN JUPYTER)\n",
    "# - Creamos estructura base dentro de ./src\n",
    "# - Esto facilita deploy en Render (Root Directory = src)\n",
    "# - Evitamos paths rotos para modelos/scripts/app\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "base = Path(\".\").resolve()\n",
    "src = base / \"src\"\n",
    "(src / \"models\").mkdir(parents=True, exist_ok=True)\n",
    "(src / \"scripts\").mkdir(parents=True, exist_ok=True)\n",
    "(src / \".streamlit\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sorted([str(p) for p in src.rglob(\"*\")])[:10], \"OK\"\n",
    "# Resultado esperado:\n",
    "# - Carpetas: src/models, src/scripts, src/.streamlit\n",
    "# - Sin errores\n",
    "\n",
    "# Interpretaci贸n:\n",
    "# - Repo preparado para ML + Streamlit + Render\n",
    "# - Separaci贸n clara entre artefactos y c贸digo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'streamlit==1.31.1\\nscikit-learn==1.4.2\\npandas==2.2.2\\nnumpy==1.26.4\\njoblib==1.4.2\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLOQUE 02\n",
    "# REQUIREMENTS (ARCHIVO PARA RENDER)\n",
    "# - Fijamos versiones para deploy reproducible\n",
    "# - Render har谩 pip install -r requirements.txt en src/\n",
    "# - Incluimos joblib para persistir el modelo\n",
    "\n",
    "req_text = \"\\n\".join([\n",
    "    \"streamlit==1.31.1\",\n",
    "    \"scikit-learn==1.4.2\",\n",
    "    \"pandas==2.2.2\",\n",
    "    \"numpy==1.26.4\",\n",
    "    \"joblib==1.4.2\",\n",
    "]) + \"\\n\"\n",
    "\n",
    "req_path = Path(\"src/requirements.txt\")\n",
    "req_path.write_text(req_text, encoding=\"utf-8\")\n",
    "\n",
    "req_path.read_text(encoding=\"utf-8\")\n",
    "# Resultado esperado:\n",
    "# - Archivo src/requirements.txt creado con 5 librer铆as\n",
    "\n",
    "# Interpretaci贸n:\n",
    "# - Mismas versiones en local y en Render\n",
    "# - Menos fallos por dependencias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit==1.31.1 (from -r src/requirements.txt (line 1))\n",
      "  Downloading streamlit-1.31.1-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting scikit-learn==1.4.2 (from -r src/requirements.txt (line 2))\n",
      "  Downloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pandas==2.2.2 (from -r src/requirements.txt (line 3))\n",
      "  Downloading pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting numpy==1.26.4 (from -r src/requirements.txt (line 4))\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib==1.4.2 (from -r src/requirements.txt (line 5))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.12/site-packages (from streamlit==1.31.1->-r src/requirements.txt (line 1)) (1.9.0)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/site-packages (from streamlit==1.31.1->-r src/requirements.txt (line 1)) (8.3.0)\n",
      "Collecting importlib-metadata<8,>=1.4 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading importlib_metadata-7.2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting packaging<24,>=16.8 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pillow<11,>=7.1.0 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting protobuf<5,>=3.20 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/site-packages (from streamlit==1.31.1->-r src/requirements.txt (line 1)) (22.0.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.12/site-packages (from streamlit==1.31.1->-r src/requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/site-packages (from streamlit==1.31.1->-r src/requirements.txt (line 1)) (2.32.5)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<9,>=8.1.0 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.12/site-packages (from streamlit==1.31.1->-r src/requirements.txt (line 1)) (4.15.0)\n",
      "Collecting tzlocal<6,>=1.1 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting validators<1,>=0.2 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading gitpython-3.1.46-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.12/site-packages (from streamlit==1.31.1->-r src/requirements.txt (line 1)) (6.5.2)\n",
      "Collecting watchdog>=2.1.5 (from streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/site-packages (from pandas==2.2.2->-r src/requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/site-packages (from pandas==2.2.2->-r src/requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn==1.4.2->-r src/requirements.txt (line 2)) (1.16.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn==1.4.2->-r src/requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit==1.31.1->-r src/requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit==1.31.1->-r src/requirements.txt (line 1)) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit==1.31.1->-r src/requirements.txt (line 1)) (2.10.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.31.1->-r src/requirements.txt (line 1))\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.12/site-packages (from importlib-metadata<8,>=1.4->streamlit==1.31.1->-r src/requirements.txt (line 1)) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/site-packages (from python-dateutil<3,>=2.7.3->streamlit==1.31.1->-r src/requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit==1.31.1->-r src/requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit==1.31.1->-r src/requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit==1.31.1->-r src/requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit==1.31.1->-r src/requirements.txt (line 1)) (2025.10.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit==1.31.1->-r src/requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit==1.31.1->-r src/requirements.txt (line 1)) (2.19.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->altair<6,>=4.0->streamlit==1.31.1->-r src/requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.31.1->-r src/requirements.txt (line 1)) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.31.1->-r src/requirements.txt (line 1)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.31.1->-r src/requirements.txt (line 1)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.31.1->-r src/requirements.txt (line 1)) (0.28.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.31.1->-r src/requirements.txt (line 1)) (0.1.2)\n",
      "Downloading streamlit-1.31.1-py2.py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading gitpython-3.1.46-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading importlib_metadata-7.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Downloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Installing collected packages: watchdog, validators, tzlocal, toml, tenacity, smmap, protobuf, pillow, packaging, numpy, joblib, importlib-metadata, cachetools, rich, pydeck, pandas, gitdb, scikit-learn, gitpython, altair, streamlit\n",
      "\u001b[2K  Attempting uninstall: protobuf\u001b[0m \u001b[32m 1/21\u001b[0m [validators]\n",
      "\u001b[2K    Found existing installation: protobuf 6.33.0\u001b[0m \u001b[32m 1/21\u001b[0m [validators]\n",
      "\u001b[2K    Uninstalling protobuf-6.33.0:\u001b[90m\u001b[0m \u001b[32m 6/21\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.33.0\u001b[0m \u001b[32m 6/21\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: pillow[0m\u001b[90m\u001b[0m \u001b[32m 6/21\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: pillow 12.0.0\u001b[0m \u001b[32m 6/21\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling pillow-12.0.0:\u001b[0m\u001b[90m\u001b[0m \u001b[32m 7/21\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled pillow-12.0.0\u001b[0m \u001b[32m 7/21\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: packaging0m\u001b[90m\u001b[0m \u001b[32m 7/21\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: packaging 25.0\u001b[0m \u001b[32m 7/21\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling packaging-25.0:[90m\u001b[0m \u001b[32m 7/21\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0\u001b[0m \u001b[32m 8/21\u001b[0m [packaging]\n",
      "\u001b[2K  Attempting uninstall: numpy\u001b[0m\u001b[90m\u001b[0m \u001b[32m 8/21\u001b[0m [packaging]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6\u001b[0m \u001b[32m 8/21\u001b[0m [packaging]\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m 9/21\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.60m\u001b[0m \u001b[32m 9/21\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: joblib[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m 9/21\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: joblib 1.5.2\u001b[0m \u001b[32m 9/21\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling joblib-1.5.2:\u001b[0m\u001b[90m\u001b[0m \u001b[32m 9/21\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled joblib-1.5.290m\u001b[0m \u001b[32m10/21\u001b[0m [joblib]\n",
      "\u001b[2K  Attempting uninstall: importlib-metadata[90m\u001b[0m \u001b[32m10/21\u001b[0m [joblib]\n",
      "\u001b[2K    Found existing installation: importlib_metadata 8.7.0\u001b[0m \u001b[32m10/21\u001b[0m [joblib]\n",
      "\u001b[2K    Uninstalling importlib_metadata-8.7.0:\u001b[0m \u001b[32m10/21\u001b[0m [joblib]\n",
      "\u001b[2K      Successfully uninstalled importlib_metadata-8.7.0\u001b[0m \u001b[32m10/21\u001b[0m [joblib]\n",
      "\u001b[2K  Attempting uninstall: rich\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m11/21\u001b[0m [importlib-metadata]\n",
      "\u001b[2K    Found existing installation: rich 14.2.0\u001b[0m \u001b[32m11/21\u001b[0m [importlib-metadata]\n",
      "\u001b[2K    Uninstalling rich-14.2.0:[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m11/21\u001b[0m [importlib-metadata]\n",
      "\u001b[2K      Successfully uninstalled rich-14.2.0\u001b[0m\u001b[90m\u001b[0m \u001b[32m13/21\u001b[0m [rich]-metadata]\n",
      "\u001b[2K  Attempting uninstall: pandas\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m14/21\u001b[0m [pydeck]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.3\u001b[0m\u001b[90m\u001b[0m \u001b[32m15/21\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling pandas-2.3.3:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m15/21\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.31m\u001b[0m\u001b[90m\u001b[0m \u001b[32m15/21\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: scikit-learn\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m15/21\u001b[0m [pandas]\n",
      "\u001b[2K    Found existing installation: scikit-learn 1.7.2\u001b[0m \u001b[32m15/21\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling scikit-learn-1.7.2:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m17/21\u001b[0m [scikit-learn]\n",
      "\u001b[2K      Successfully uninstalled scikit-learn-1.7.2\u001b[0m\u001b[90m\u001b[0m \u001b[32m17/21\u001b[0m [scikit-learn]\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m21/21\u001b[0m [streamlit]21\u001b[0m [streamlit]rn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed altair-5.5.0 cachetools-5.5.2 gitdb-4.0.12 gitpython-3.1.46 importlib-metadata-7.2.1 joblib-1.4.2 numpy-1.26.4 packaging-23.2 pandas-2.2.2 pillow-10.4.0 protobuf-4.25.8 pydeck-0.9.1 rich-13.9.4 scikit-learn-1.4.2 smmap-5.0.2 streamlit-1.31.1 tenacity-8.5.0 toml-0.10.2 tzlocal-5.3.1 validators-0.35.0 watchdog-6.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.20.0 requires protobuf>=5.28.0, but you have protobuf 4.25.8 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLOQUE 03\n",
    "# INSTALACION LOCAL (OPCIONAL SI YA ESTA INSTALADO)\n",
    "# - Instalamos dependencias desde requirements\n",
    "# - Esto es 煤til en Codespace/Jupyter para correr el entrenamiento\n",
    "# - Si tu entorno ya tiene todo, este bloque no es necesario\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"src/requirements.txt\"])\n",
    "# Resultado esperado:\n",
    "# - Instalaci贸n exitosa sin errores\n",
    "\n",
    "# Interpretaci贸n:\n",
    "# - Entorno listo para entrenar y correr Streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, 0.9333333333333333)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLOQUE 04\n",
    "# ENTRENAMIENTO REPRODUCIBLE (IRIS + DECISION TREE)\n",
    "# - Usamos dataset Iris (sklearn) para clasificaci贸n\n",
    "# - Entrenamos DecisionTree con random_state=42\n",
    "# - Guardamos modelo + m茅tricas en src/models\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from joblib import dump\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "    \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist(),\n",
    "    \"classification_report\": classification_report(y_test, y_pred, output_dict=True),\n",
    "    \"feature_names\": list(X.columns),\n",
    "    \"target_names\": list(iris.target_names),\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "}\n",
    "\n",
    "model_path = Path(\"src/models/decision_tree_classifier_default_42.joblib\")\n",
    "metrics_path = Path(\"src/models/metrics_default_42.json\")\n",
    "\n",
    "dump(model, model_path)\n",
    "metrics_path.write_text(json.dumps(metrics, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "model_path.exists(), metrics_path.exists(), metrics[\"accuracy\"]\n",
    "# Resultado esperado:\n",
    "# - True, True, y un accuracy ~0.9+ (aprox)\n",
    "# - Archivos guardados en src/models/\n",
    "\n",
    "# Interpretaci贸n:\n",
    "# - Ya tenemos un modelo listo para ser consumido por la webapp\n",
    "# - Persistencia permite deploy sin reentrenar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 'versicolor')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLOQUE 05\n",
    "# VALIDACION RAPIDA DEL ARTEFACTO (CARGA DEL MODELO)\n",
    "# - Verificamos que el modelo se puede cargar desde disco\n",
    "# - Hacemos una predicci贸n de prueba con un input v谩lido\n",
    "# - Detectamos errores de paths antes de Streamlit/Render\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "loaded_model = load(\"src/models/decision_tree_classifier_default_42.joblib\")\n",
    "sample = np.array([[5.8, 3.0, 4.0, 1.3]], dtype=float)\n",
    "pred = int(loaded_model.predict(sample)[0])\n",
    "\n",
    "pred, metrics[\"target_names\"][pred]\n",
    "# Resultado esperado:\n",
    "# - Un entero 0/1/2 y su clase (setosa/versicolor/virginica)\n",
    "\n",
    "# Interpretaci贸n:\n",
    "# - El artefacto es usable para inferencia\n",
    "# - El deploy podr谩 cargar el modelo sin problemas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# comments: Streamlit runtime configuration for cloud deployments.\\n[server]\\nheadless = true\\nenableCORS = false\\nenableXsrfProtection = false\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLOQUE 06\n",
    "# CONFIG STREAMLIT PARA CLOUD (RENDER)\n",
    "# - Config headless y desactiva CORS/XSRF para evitar fricci贸n en deploy\n",
    "# - Este archivo vive dentro de src/.streamlit/\n",
    "# - Es una configuraci贸n com煤n para servicios tipo Render\n",
    "\n",
    "config_text = \"\\n\".join([\n",
    "    \"# comments: Streamlit runtime configuration for cloud deployments.\",\n",
    "    \"[server]\",\n",
    "    \"headless = true\",\n",
    "    \"enableCORS = false\",\n",
    "    \"enableXsrfProtection = false\",\n",
    "]) + \"\\n\"\n",
    "\n",
    "config_path = Path(\"src/.streamlit/config.toml\")\n",
    "config_path.write_text(config_text, encoding=\"utf-8\")\n",
    "\n",
    "config_path.read_text(encoding=\"utf-8\")\n",
    "# Resultado esperado:\n",
    "# - Archivo src/.streamlit/config.toml creado\n",
    "\n",
    "# Interpretaci贸n:\n",
    "# - Menos errores en Render\n",
    "# - App m谩s estable en cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2179)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLOQUE 07\n",
    "# CREAR APP STREAMLIT (src/app.py)\n",
    "# - App carga modelo + m茅tricas desde src/models\n",
    "# - UI con sliders y bot贸n Predict\n",
    "# - Listo para Start Command en Render\n",
    "\n",
    "app_code = r'''\n",
    "# comments: Streamlit app to serve a trained Iris classifier.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from joblib import load\n",
    "\n",
    "\n",
    "def load_artifacts() -> tuple[object, dict]:\n",
    "    base_dir = Path(__file__).resolve().parent\n",
    "    model_path = base_dir / \"models\" / \"decision_tree_classifier_default_42.joblib\"\n",
    "    metrics_path = base_dir / \"models\" / \"metrics_default_42.json\"\n",
    "\n",
    "    model = load(model_path)\n",
    "    metrics = json.loads(metrics_path.read_text(encoding=\"utf-8\"))\n",
    "    return model, metrics\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    st.set_page_config(page_title=\"Iris Predictor\", page_icon=\"\", layout=\"centered\")\n",
    "\n",
    "    st.title(\" Iris - Predicci贸n con Decision Tree\")\n",
    "    st.markdown(\"Ajusta los valores y ejecuta una predicci贸n del tipo de Iris.\")\n",
    "\n",
    "    model, metrics = load_artifacts()\n",
    "    feature_names = metrics[\"feature_names\"]\n",
    "    target_names = metrics[\"target_names\"]\n",
    "\n",
    "    st.sidebar.header(\"锔 Par谩metros del modelo\")\n",
    "    st.sidebar.write(f\"Accuracy (test): **{metrics['accuracy']:.4f}**\")\n",
    "    st.sidebar.write(\"random_state: **42**\")\n",
    "\n",
    "    st.subheader(\"И Inputs\")\n",
    "\n",
    "    # comments: Use realistic Iris ranges with safe defaults.\n",
    "    val1 = st.slider(feature_names[0], min_value=4.0, max_value=8.0, value=5.8, step=0.1)\n",
    "    val2 = st.slider(feature_names[1], min_value=2.0, max_value=4.5, value=3.0, step=0.1)\n",
    "    val3 = st.slider(feature_names[2], min_value=1.0, max_value=7.0, value=4.0, step=0.1)\n",
    "    val4 = st.slider(feature_names[3], min_value=0.1, max_value=2.6, value=1.3, step=0.1)\n",
    "\n",
    "    X = np.array([[val1, val2, val3, val4]], dtype=float)\n",
    "\n",
    "    if st.button(\" Predict\"):\n",
    "        pred = int(model.predict(X)[0])\n",
    "        st.success(f\"Predicci贸n: **{target_names[pred]}**\")\n",
    "\n",
    "        proba = getattr(model, \"predict_proba\", None)\n",
    "        if callable(proba):\n",
    "            probs = proba(X)[0]\n",
    "            st.write(\"Probabilidades:\")\n",
    "            st.json({target_names[i]: float(probs[i]) for i in range(len(target_names))})\n",
    "\n",
    "    st.divider()\n",
    "    st.caption(\"Deploy en Render: streamlit run app.py --server.port $PORT --server.address 0.0.0.0\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "app_path = Path(\"src/app.py\")\n",
    "app_path.write_text(app_code.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "app_path.exists(), app_path.stat().st_size\n",
    "# Resultado esperado:\n",
    "# - True y un tama帽o > 0\n",
    "\n",
    "# Interpretaci贸n:\n",
    "# - Ya existe la webapp\n",
    "# - Solo falta correr local y desplegar en Render\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'streamlit run src/app.py'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLOQUE 08\n",
    "# CORRER STREAMLIT LOCAL (COMANDO)\n",
    "# - Validamos UI y predicciones antes de deploy\n",
    "# - En Jupyter solo imprimimos el comando para copiar/pegar\n",
    "# - Esto evita colgar el notebook con un servidor interactivo\n",
    "\n",
    "cmd = \"streamlit run src/app.py\"\n",
    "cmd\n",
    "# Resultado esperado:\n",
    "# - Se imprime: streamlit run src/app.py\n",
    "\n",
    "# Interpretaci贸n:\n",
    "# - Copias y pegas en terminal\n",
    "# - Si corre local, Render casi seguro tambi茅n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'streamlit run src/app.py'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLOQUE 08\n",
    "# CORRER STREAMLIT LOCAL (COMANDO)\n",
    "# - Validamos UI y predicciones antes de deploy\n",
    "# - En Jupyter solo imprimimos el comando para copiar/pegar\n",
    "# - Esto evita colgar el notebook con un servidor interactivo\n",
    "\n",
    "cmd = \"streamlit run src/app.py\"\n",
    "cmd\n",
    "# Resultado esperado:\n",
    "# - Se imprime: streamlit run src/app.py\n",
    "\n",
    "# Interpretaci贸n:\n",
    "# - Copias y pegas en terminal\n",
    "# - Si corre local, Render casi seguro tambi茅n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
